{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Detection in Video Using Deep Learning\n",
    "### 2018/02/19 4th Meeting  Xiaolong Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A short summary\n",
    "During the past 2 weeks:\n",
    "- Notes on last meeting \n",
    "- Sample Video with EAST detector [Link in Drive](https://drive.google.com/open?id=1QeFyVRk-KVYUkVgCdzkMD_A8zRMTgTdq)\n",
    "- Papers followed these days [Link in Drive](https://drive.google.com/open?id=1IpJvGVpZgEIs-4HxGq9LcXc6nsFJs4m4)\n",
    "- Deep Learning Workshop [Link in Drive](https://docs.google.com/presentation/d/1ORASeJsawu8zZciMzeM3eoGfQqgpHrjwymuAnojysMI/edit#slide=id.p)\n",
    "- Network Design and Notes [Link in Drive](https://drive.google.com/file/d/1GcbeA2chl5KiYyx8w5F-Q9dHbOphwv3P/view?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Research Details\n",
    "### 2.1 Problem Definition\n",
    "Given a video with text patchs in the image frames, the pattern may be machine-printed, or hand-writing, with different levels of distortion, occlusion, and other environmental noise, we need to detect the text regions precisely and quickly(>16fps), and for some specific occasions, we may also need to recognize the text.\n",
    "\n",
    "### 2.2 Methods \n",
    "#### 'Strategy 1':\n",
    "Use CNN as an encoder to reduce the frames into features vector, feed both boxes prediction after NMS in EAST paper and last conv feature layer after average pooling into LSTM RNN, and trying to produce text boxes predictions for each frame\n",
    "#### 'Strategy 2':\n",
    "Instead of feeding predicted boxes after NMS, we will feed into Score Map+RBOX geometry+ Rotation angle before NMS into LSTM\n",
    "\n",
    "### 2.3 Works done:\n",
    "- LSTM framework in Tensorflow tested on language model for words prediction\n",
    "- Save last conv features and predicted boxes coordinates and socres into Json file for 301 frames\n",
    "- Import Groundtruth text region labels from XML file\n",
    "- Data import function to LSTM(under debugging)\n",
    "\n",
    "### 2.4 Challenges:\n",
    "The ROLO (Rrecurrent YOLO) paper actually only track one object in one frame, and feed in all the boxes prediction(boxes prediction at 7*7 grid) \n",
    "before NMS into LSTM, and here we are trying to use RNN to track multiple text objects at the same time, so it would be a little bit difficult.\n",
    "\n",
    "### 2.5 Questions:\n",
    "- There are 301 frames in a sample video from ICDAR, the EAST text detector would predict 1 - 15 bounding boxes after NMS, while the ground truth from ICDAR may vary from 5 - 40 boxes for each frame. However the LSTM RNN cell I adopted now needs to receive input X[t] with fixed length, and produce fixed length of output vector Y[t] for each frame, is there better strategy than making the default input 15 boxes and output 40 boxes?  The seq2seq or encoder-decoder structure could take varied length for in and out, however it might not be suitable here.\n",
    "- Feature layer has 32 channels, and (120, 168) for each, which is too big for RNN, how should we reduce the demension\n",
    "  for it?\n",
    "- A simple algorithm to match predicted boxes with groundtruth boxes when the 4 points of the box is given.\n",
    "- The research goal with timeline I need to set now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary and To-dos\n",
    "For Question 1, Prof. Abbott suggests that we could first refer to those traditional multi-oject tracking research like cells tracking, also review some new papers on multi-agent tracking in top conferences; meanwhile, to make things simple, I could first start from tracking only one box each time, but the challenge is that both predicted boxes and ground-truth boxes are multiple, how could I pick out the one I want to follow in every frame. \n",
    "\n",
    "- RNN debug with Input(`Already Done by this Thursday`)\n",
    "- Search for papers about multiple agents tracking problem in video\n",
    "- Hyperparameters tuning like number of steps, LSTM layer number, also data augmentation(Training details)\n",
    "- Totally Understand the data flow and backpropagation with RNN(`Done by this Thursday`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
