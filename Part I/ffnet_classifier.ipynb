{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T15:29:26.331001Z",
     "start_time": "2018-01-17T15:29:25.522327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T15:29:28.455327Z",
     "start_time": "2018-01-17T15:29:28.340759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Creates a graph.\n",
    "# with tf.device('/gpu:0'):\n",
    "#   a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "#   b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "# c = tf.matmul(a, b)\n",
    "# # Creates a session with log_device_placement set to True.\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# # Runs the op.\n",
    "# print(sess.run(c))\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T15:29:33.017066Z",
     "start_time": "2018-01-17T15:29:33.009856Z"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Data import with Dataset\n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(...)  # Parse the record into tensors.\n",
    "dataset = dataset.repeat()  # Repeat the input indefinitely.\n",
    "dataset = dataset.batch(32)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "# You can feed the initializer with the appropriate filenames for the current\n",
    "# phase of execution, e.g. training vs. validation.\n",
    "\n",
    "# Initialize `iterator` with training data.\n",
    "training_filenames = [\"train-00000-of-00001\"]\n",
    "train = sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "\n",
    "# Initialize `iterator` with validation data.\n",
    "# validation_filenames = [\"validation-00000-of-00001\"]\n",
    "# val = sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T15:29:51.693709Z",
     "start_time": "2018-01-17T15:29:51.687311Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "################lower level definition################\n",
    "# weight initialization,\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return(tf.Variable(initial))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# convolution and pool predefine for boundary, stride\n",
    "def conv2d(x, W, padding = 'SAME'):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=padding)\n",
    "\n",
    "# max pooling \n",
    "def max_pool_2x2(x, padding = 'SAME'):\n",
    "    return tf.nn.max_pool(x, strides= [1, 2, 2, 1], ksize=[1, 2, 2,1], padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T15:30:14.153225Z",
     "start_time": "2018-01-17T15:30:14.113096Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# define FFnet unit \n",
    "\n",
    "from keras.layers import Dense, Conv2D, Flatten, BatchNormalization\n",
    "def ffnet_module(X, f, filters , stage, block, s = 2 ):\n",
    "    \"\"\"\n",
    "    Implementation of the figure above, with 3 standard 3*3*64 module for the general module, and one fast-forwarding path\n",
    "    Arguments: \n",
    "    X--      the input tensor with shape (n_H, n_W, n_C)\n",
    "    f--      filter kernel size\n",
    "    filters: number of filters in each layer\n",
    "    stage  : name of stage \n",
    "    block  : string/character, used to name the layers, depending on \n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    conv_name_base = 'ffnet' + str(stage) + block + 'conv_branch'\n",
    "    bn_name_base   = 'bn' + str(stage) + block + 'bn_branch'\n",
    "    fast_fwd_base  = 'ffnet' + str(stage) + block + 'fast_branch' \n",
    "    \n",
    "    # Retrieve filters \n",
    "    F1, F2, F3 = filters\n",
    "    f1, f2     = f\n",
    "    \n",
    "    # Save the input value\n",
    "    X_fast = X\n",
    "    \n",
    "    ####### Main Path ######\n",
    "    X = Conv2D(filters = F1, kernel_size = (f1, f1), strides = (1, 1), padding = 'valid', name = conv_name_base + '1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base+'1')(X)\n",
    "    X = tf.nn.relu(X)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f1, f1), strides = (1, 1), padding = 'valid', name = conv_name_base + '2')(X)\n",
    "    #X = BatchNormalization(axis = 3, name = bn_name_base+'2')(X)\n",
    "    X = tf.nn.relu(X)\n",
    "    X = Conv2D(filters = F3, kernel_size = (f1, f1), strides = (1, 1), padding = 'same', name = conv_name_base + '3')(X)\n",
    "    #X = BatchNormalization(axis = 3, name = bn_name_base + '3')(X)\n",
    "    X = tf.nn.relu(X)\n",
    "    ####### fast forward ###### \n",
    "    X_fast = Conv2D(filters = 16, kernel_size = (f2, f2), strides = (1, 1), padding = 'valid', name = fast_fwd_base + '1')(X_fast)\n",
    "    #X_fast = BatchNormalization(axis = 3, name = bn_name_base + 'fast')\n",
    "    X_fast = tf.nn.relu(X_fast)\n",
    "    ###### Final step: concatation #######\n",
    "    \n",
    "    return tf.concat([X, X_fast], 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T15:30:46.647995Z",
     "start_time": "2018-01-17T15:30:46.547942Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "################# start to build up our model !###############\n",
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 2])\n",
    "# the first convolutional layer \n",
    "conv_1 = weight_variable([5, 5, 3, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "#x_image = tf.reshape(x, [-1, 32, 32, 3])\n",
    "h_conv1 = tf.nn.relu(conv2d(x, conv_1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# the second convolutional layer+relu+ \n",
    "conv_2 =  weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, conv_2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "ffnet = ffnet_module(h_pool1, f = [3, 5], filters = [64, 64, 64] , stage = 1, block = 'a', s = 1 )\n",
    "# dense connected layer 1\n",
    "W_fc1 = weight_variable([8*8*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "hpool_flat = tf.reshape(h_pool2, [-1, 8*8*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(hpool_flat, W_fc1) + b_fc1)\n",
    "# dense connected layer 2, etc\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "# dense connected layer 3, etc\n",
    "W_fc3 = weight_variable([10, 2])\n",
    "b_fc3 = bias_variable([2])\n",
    "# Dropout design\n",
    "prob = tf.placeholder(tf.float32)\n",
    "h_fc1dropout = tf.nn.relu(tf.nn.dropout(h_fc1, prob))\n",
    "h_fc2= tf.matmul(h_fc1dropout, W_fc2) + b_fc2\n",
    "# output channel [node1, node2]\n",
    "y_conv = tf.matmul(h_fc2, W_fc3) + b_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# import data in the format of tf.\n",
    "height=tf.constant(32, dtype=tf.int32)\n",
    "width =tf.constant(32, dtype=tf.int32)\n",
    "def read_and_decode(filename, batch_size, num_epochs):\n",
    "    reader = tf.TFRecordReader()\n",
    "    filename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "            'image/height': tf.FixedLenFeature([], tf.int64),\n",
    "            'image/width': tf.FixedLenFeature([], tf.int64),\n",
    "            'image/colorspace': tf.FixedLenFeature([], dtype=tf.string,default_value=''),\n",
    "            'image/channels':  tf.FixedLenFeature([], tf.int64),            \n",
    "            'image/class/label': tf.FixedLenFeature([],tf.int64),\n",
    "            'image/class/text': tf.FixedLenFeature([], dtype=tf.string,default_value=''),\n",
    "            'image/format': tf.FixedLenFeature([], dtype=tf.string,default_value=''),\n",
    "            'image/filename': tf.FixedLenFeature([], dtype=tf.string,default_value=''),\n",
    "            'image/encoded': tf.FixedLenFeature([], dtype=tf.string, default_value='')\n",
    "      })\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "    # [mnist.IMAGE_PIXELS].\n",
    "#     image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "#     image.set_shape([mnist.IMAGE_PIXELS])\n",
    "    label = features['image/class/label']\n",
    "    image_buffer = features['image/encoded']\n",
    "\n",
    "    # Decode the jpeg\n",
    "    with tf.name_scope('decode_jpeg',[image_buffer], None):\n",
    "        # decode\n",
    "        image = tf.image.decode_jpeg(image_buffer, channels=3)\n",
    "        \n",
    "        # resize\n",
    "        image = tf.image.resize_images(image, [height, width])\n",
    "    \n",
    "        # and convert to single precision data type\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    # OPTIONAL: Could reshape into a 28x28 image and apply distortions\n",
    "    # here.  Since we are not applying any distortions in this\n",
    "    # example, and the next step expects the image to be flattened\n",
    "    # into a vector, we don't bother.\n",
    "\n",
    "    # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "    image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
    "    print(image.shape)\n",
    "    #image=tf.reshape(image,[height*width*3])\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(label, tf.int32)  \n",
    "#     images, sparse_labels = tf.train.shuffle_batch(\n",
    "#         [image, label], batch_size=batch_size, num_threads=2,\n",
    "#         capacity=1000 + 3 * batch_size,\n",
    "#         # Ensures a minimum amount of shuffling of examples.\n",
    "#         min_after_dequeue=1000)\n",
    "    return image, label\n",
    "images, labels = read_and_decode(\"train-00000-of-00001\", 1, 10)\n",
    "vimages, vlabels = read_and_decode(\"validation-00000-of-00001\", 1, 10)\n",
    "# training examples \n",
    "imageBatch, labelBatch = tf.train.shuffle_batch(\n",
    "    [images, labels], batch_size=100,\n",
    "    capacity=2000,\n",
    "    min_after_dequeue=1000)\n",
    "# and similarly for the validation data \n",
    "vimageBatch, vlabelBatch = tf.train.shuffle_batch(\n",
    "    [vimages, vlabels], batch_size=1,\n",
    "    capacity=2000,\n",
    "    min_after_dequeue=1000)\n",
    "# # interactive session allows inteleaving of building and running steps\n",
    "# sess = tf.InteractiveSession()\n",
    "# batch_size =  100\n",
    "# dataset_train = dataset_train.batch(batch_size)\n",
    "# iterator = dataset_train.make_one_shot_iterator()\n",
    "# batch_features, batch_labels = iterator.get_next()\n",
    "sess = tf.InteractiveSession()\n",
    "print(imageBatch.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# explore ways to iomport data: to import data in an iterative style, while aslo assign data and labels dynamically\n",
    "######1. Create Dataset object #######\n",
    "# function for image reading\n",
    "import cv2\n",
    "def read_patch_cv2(filename, label):\n",
    "    image_decoded = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "    print('here I come')\n",
    "    return image_decoded, label\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)#labels are not put here \n",
    "    image = tf.image.decode_image(image_string, channels =  3)\n",
    "    print('Transforming')\n",
    "    return image, label\n",
    "\n",
    "def imgs_input_fn(filenames, labels = None):\n",
    "    # create labels if there is no source\n",
    "    if labels is None:\n",
    "        labels = [0]*len(filenames)\n",
    "    labels = np.array(labels)\n",
    "    # to avoid \n",
    "    if len(labels) == 1:\n",
    "        np.expand_dims(labels, axis = 1)\n",
    "    # convert array/list into tensorflow constants\n",
    "    filenames = tf.constant(filenames)\n",
    "    labels = tf.constant(labels)\n",
    "    #abels = tf.cast(labels, tf.float32)\n",
    "    # apply standard tf function mapping images data to dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    return dataset\n",
    "\n",
    "def read_txt(filepath, prefix):\n",
    "    filenames = []\n",
    "    labels= []\n",
    "    # read from text files \n",
    "    with open(filepath, 'r') as f:\n",
    "        num = 0\n",
    "        for line in f:\n",
    "            num +=1 \n",
    "            line = line.strip()\n",
    "            if num < 1:\n",
    "                print('%s'  %(line[:-2]) )\n",
    "                print(line[-1])\n",
    "            filenames.append(prefix+line[:-2])\n",
    "            labels.append(line[-1])\n",
    "    print(num)\n",
    "    return filenames, labels\n",
    "    \n",
    "#print(filenames)\n",
    "filepath_train = '/home/dragonx/Documents/text_detect/dataC/COCO-Text-Patch/train.txt'\n",
    "filepath_val = '/home/dragonx/Documents/text_detect/dataA/COCO-Text-Patch/val.txt'\n",
    "filenames_train, labels_train = read_txt(filepath_train, './dataC/COCO-Text-Patch/images/')\n",
    "filenames_val, labels_val = read_txt(filepath_val, './dataA/COCO-Text-Patch/images/')\n",
    "dataset_train = imgs_input_fn(filenames_train, labels_train)\n",
    "dataset_val   = imgs_input_fn(filenames_val, labels_val)\n",
    "######2. batch_read() ####### \n",
    "#either from file directory, or by the txt file with filenames  \n",
    "\n",
    "######3. Create tfRecord Object #######\n",
    "\n",
    "#(recommended)\n",
    "######4. Read from npy format(one by one or in total)  #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Data import with Dataset\n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(...)  # Parse the record into tensors.\n",
    "dataset = dataset.repeat()  # Repeat the input indefinitely.\n",
    "dataset = dataset.batch(32)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "# You can feed the initializer with the appropriate filenames for the current\n",
    "# phase of execution, e.g. training vs. validation.\n",
    "\n",
    "# Initialize `iterator` with training data.\n",
    "training_filenames = [\"train-00000-of-00001\"]\n",
    "train = sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "\n",
    "# Initialize `iterator` with validation data.\n",
    "# validation_filenames = [\"validation-00000-of-00001\"]\n",
    "# val = sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dragonx/Documents/text_detect\r\n"
     ]
    }
   ],
   "source": [
    "# make sure the directory is correct\n",
    "!pwd\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name='C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(indices=labels, depth=C, axis=0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108012\n",
      "122324\n",
      "['./dataC/COCO-Text-Patch/images/txt/txt_615639.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_660131.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_235518.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_734094.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_336638.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_374506.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_127162.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_713484.jpg'\n",
      " './dataC/COCO-Text-Patch/images/txt/txt_43367.jpg']\n"
     ]
    }
   ],
   "source": [
    "# self defined data import as numpy array\n",
    "import os\n",
    "import cv2\n",
    "train_dir = './dataC/COCO-Text-Patch/images/'\n",
    "val_dir =   './dataA/COCO-Text-Patch/images/'\n",
    "classes = ['txt', 'nontxt']\n",
    "fname_tr   = []\n",
    "labels_tr  = []\n",
    "fname_val  = []\n",
    "labels_val = []\n",
    "for i, c in enumerate(classes):\n",
    "    buffer = os.listdir(train_dir+c)\n",
    "    buffer = [train_dir+c+'/'+x for x in buffer]\n",
    "    fname_tr.extend(buffer[:])\n",
    "    labels_tr.extend([i]*len(buffer))\n",
    "    # the same for val\n",
    "    buffer = os.listdir(val_dir+c)\n",
    "    buffer = [val_dir+c+'/'+x for x in buffer]\n",
    "    fname_val.extend(buffer[:])\n",
    "    labels_val.extend([i]*len(buffer))\n",
    "\n",
    "print(len(fname_tr))\n",
    "print(len(fname_val))\n",
    "# print(fname_tr[0:100])\n",
    "# check if numbers are correct\n",
    "assert len(fname_tr) == len(labels_tr)\n",
    "index_tr = np.arange(0, len(labels_tr))  \n",
    "index_val= np.arange(0, len(labels_val))  \n",
    "def imread_batch(filenames, labels):\n",
    "    train_data = np.zeros([len(filenames), 32, 32, 3])\n",
    "    for i, f in enumerate(filenames):\n",
    "        #print(f)\n",
    "        buffer = cv2.imread(f)\n",
    "        train_data[i, :,:,:] = buffer[:,:,:]\n",
    "        #print(buffer.shape)\n",
    "    labels = one_hot_matrix(labels, 2).T\n",
    "    \n",
    "    return train_data, labels\n",
    "\n",
    "#data_tr, labels_tr = imread_batch(fname_tr[0:100], labels_tr[0:100])\n",
    "#data_val,labels_val = imread_batch(fname_val[0:100], labels_val[0:100])\n",
    "# data_tr, labels_tr = imread_batch(fname_tr(index_tr[0:100]) , labels_tr[0:100])\n",
    "print(np.take(fname_tr, index_tr[1:10], axis = 0))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 32, 32, 3)\n",
      "(99, 2)\n"
     ]
    }
   ],
   "source": [
    "# input data produce\n",
    "data_batch, labels_batch = imread_batch(fname_tr[1:100], labels_tr[1:100]);print(data_batch.shape)\n",
    "print(labels_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    }
   ],
   "source": [
    "############ for training detail ##############\n",
    "# x, y_: input labels\n",
    "# y_conv: convolutional layers output\n",
    "from random  import shuffle\n",
    "import time\n",
    "# loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y_conv))\n",
    "# optimizer and learning rate\n",
    "train_step   = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "# how to decide the prediction and accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# train process \n",
    "batch_size = 50\n",
    "epoch_num  = 200\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_tr = np.floor(len(labels_tr)/batch_size)\n",
    "    num_val = np.floor(len(labels_val)/batch_size)\n",
    "    for i in range(epoch_num):\n",
    "        start_time = time.time()\n",
    "        print('epoch %d'%(i) )\n",
    "        # random batch in every iteration\n",
    "        shuffle(index_tr)\n",
    "        for j in range(np.int64(num_tr)):\n",
    "            # data preparation\n",
    "            sub_time = time.time()\n",
    "            filenames_batch = np.take(fname_tr, index_tr[batch_size*(j) :min(batch_size*(j+1), len(labels_tr))], axis = 0)\n",
    "            labels_batch    = np.take(labels_tr, index_tr[batch_size*(j):min(batch_size*(j+1),len(labels_tr))] ,axis = 0)\n",
    "            data_batch, labels_batch = imread_batch(filenames_batch, labels_batch);#print(data_batch.shape)\n",
    "            # train the network from scratch using GPU\n",
    "            train_step.run(feed_dict = {x: data_batch, y_ :labels_batch, prob:0.5})\n",
    "            # print('load & training time on %d images is %f'%(batch_size, time.time()-sub_time))\n",
    "        # model evaluation with val dataset\n",
    "        train_accuracy = accuracy.eval(feed_dict = {x: data_batch, y_ : labels_batch, prob: 1})\n",
    "        print('current accuracy on %d images is %f'%(batch_size, train_accuracy))\n",
    "        # training time evaluation with timer\n",
    "        # provide checkpoints for tensorboard usage\n",
    "        # data visualization & model summary                                        \n",
    "#         if i % 10 == 0:\n",
    "#             train_accuracy = accuracy.eval(feed_dict = {x: , y_ : labelBatch, prob: 1})\n",
    "#             print('step %d, training accuracy %g' %(i, train_accuracy))\n",
    "#         filenames_batch = np.take(fname_tr, index_tr[batch_size*(j):batch_size*(j+1)], axis = 0)\n",
    "#         labels_batch    = np.take(labels_tr, index_tr[batch_size*(i):batch_size*(i+1)], axis = 0)\n",
    "#         data_batch, labels_batch = imread_batch(filenames_batch, labels_batch)\n",
    "#         print('test accuracy %g' %accuracy.eval(feed_dict = {x: vimageBatch, y_: vimageBatch, prob : 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
